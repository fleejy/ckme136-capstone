---
title: "Analysis Notebook"
author: "Jae Yong (Francisco) Lee"
date: '2018-11-19'
output:
  pdf_document: default
  html_notebook: default
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(formatR)
# Set to wrap long lines in R
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```
## Data Preparation

Data was sourced from [Kaggle](https://www.kaggle.com/center-for-medicare-and-medicaid/hospital-ratings)
```{r}
setwd("~/repos/ckme136-capstone/")
hoq <- read.csv(file="dataset/final_hoq.csv", header = TRUE, stringsAsFactors=TRUE)
str(hoq)

# Create ordered levels
hoq$h_mortality <- ordered(hoq$h_mortality, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_soc <- ordered(hoq$h_soc, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_ra <- ordered(hoq$h_ra, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_pex <- ordered(hoq$h_pex, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_eoc <- ordered(hoq$h_eoc, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_toc <- ordered(hoq$h_toc, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
hoq$h_imaging <- ordered(hoq$h_imaging, levels = c("'Not Available'", "'Below the national average'", "'Same as the national average'", "'Above the national average'"))
```
The hospital overall rating was categorized based on the literature review where ratings of 4 or above are considered to have high quality (Low Hospital Quality was abbreviated to LHQ and High Hospital Quality was abbreviated to HHQ).
``` {r}
hoq$h_rating <- cut(hoq$h_rating, breaks=c(0, 3, 5), labels=c("LHQ", "HHQ"))
write.csv(hoq, file = "nomRating.csv")
str(hoq)
```
Afterwards, *nomRating.csv* was balanced and renamed to *nomRating-balanced.csv*. False instances were down sampled to match the true instances (i.e., from 2435 to 964).

# Methodology

Classification methods will be used to predict the overall hospital rating and identify the characteristics of hospitals. For predictive modelling, three classification algorithms will be explored: (1) decision tree, (2) NaÃ¯ve Bayes, and (3) logistic regression.

### Decision Tree

The first classification algorithm applied to the dataset was the decision tree model. The technique was realized through the use of [Weka](https://www.cs.waikato.ac.nz/ml/weka/) and the built-in J48 Decision Tree classifier. With the prepared dataset, initial assessment of the model displayed high accuracy rate. However, the primary metric of success of recall were significantly lower compared to the overall accuracy rate. Since 85.5% of the class attribute were FALSE, the model was biased toward the FALSE instances and resulted in high overall accuracy at the cost of low recall on TRUE instances. For the next iteration, F score will also be examined.

### Logistic Regression
```{r}
#install.packages("plyr")
#install.packages("corrplot")
#install.packages("gridExtra")
#install.packages("ggthemes")
#install.packages("caret")
#install.packages("MASS")
#install.packages("gplots")
library(gridExtra)
library(ggthemes)
library(caret)
library(MASS)
library(plyr)
library(corrplot)
library(ggplot2)
library(gplots)
```
Data Preparation

**Dealing with imbalanced class distribution**
Answers online: 
For logistic regression in particular, there was absolutely no benefit to creating a balanced sample. What was far more important was using all the data you had available. 

For logistic regression models unbalanced training data affects only the estimate of the model intercept (although this of course skews all the predicted probabilities, which in turn compromises your predictions). Fortunately the intercept correction is straightforward: Provided you know, or can guess, the true proportion of 0s and 1s and know the proportions in the training set you can apply a rare events correction to the intercept.

**How to remove outliers from dataset**
Unsolved

```{r}
#Import dataset
hoq <- read.csv(file="../dataset/final_hoq.csv", header = TRUE)
str(hoq)
```

Descriptive statistics for the attributes.
Check if there are any missing values in each attributes.
-There are no missing values for all attributes. 
```{r pressure, echo=FALSE}

summary(hoq)

sapply(hoq,function(x) sum(is.na(x)))
```

Correlation between categorical attributes. Checking if categorical variables are independent can be done with Chi-Squared test of independence.

If we assume that a given set of variables are independent, then the values of the contingency table for these variables should be distributed uniformly. After, we check how far away from uniform the actual values are.
-The Day Charge and Day minutes are correlated. So one of them will be removed from the model. We remove Day Charge. We also remove Eve Charge, Night Charge and Intl.Charge for the same reason.
```{r}
# Convert data as a table
dt <- as.table(as.matrix(hoq))

# Graph
balloonplot(t(dt), main="Hospital Overall Ratings", xlab="", ylab="", label=FALSE, show.margins=FALSE)
```
### Naive Bayes
```{r}
##install.packages("e1071")
library("e1071")
#hoq_df <- read.csv('~/repos/ckme136-capstone/dataset/')
#names(hoq_df)
```